# -*- coding: utf-8 -*-
"""ML_Group_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZM1nNAourMX8C1oFNIU4pUUHCu9r7KRn
"""

pip install opendatasets

import opendatasets as od

od.download("https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud/code")

import os

os.listdir()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import warnings
warnings.filterwarnings("ignore")

data = pd.read_csv('/content/creditcardfraud/creditcard.csv', sep=',')
data.head()

missing = data.isnull().sum()
percentage = (100*data.isnull().sum()/data.count())
pd.concat([missing, percentage], axis=1, keys=['Missing values', 'Percentage']).transpose()

duplicates = data.duplicated().sum()
duplicates

data.shape

data = data.drop_duplicates(keep = False)
data.shape

number_of_fraud = data['Class'].sum()
total_fraud = data['Class'].count()
percentage_of_fraud = 100 * number_of_fraud / total_fraud

# Displays the percentage of fraudulent transactions
print(f'Number of fraudulent operations --> {number_of_fraud}')
print(f'Total number of operations --> {total_fraud}')
print(f'Percentage of fraudulent operations --> {percentage_of_fraud:.2f}%')

mediafraudulentas = data[data.Class == 1]['Amount'].mean()

# Displays the average amount of fraudulent transactions
print(f'Average amount of fraudulent transactions --> {mediafraudulentas:.2f}')

number_of_no_fraud = total_fraud - number_of_fraud
total_no_fraud = total_fraud
percentage_of_no_fraud = 100 * number_of_no_fraud / total_fraud

fig, ax = plt.subplots()
gbarras = ax.bar(['No Fraud', 'Fraud'], [number_of_no_fraud, number_of_fraud], color=['tab:green', 'red'])
ax.set_title('No fraud vs Fraud')
ax.set_ylabel('Number of operations')
ax.set_xlabel('Type of operations')
for bar in gbarras:
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2, height, f'{height}', ha='center', va='bottom')
plt.show()

data_fraudulentas = data[data.Class == 1]['Amount']
data_fraudulentas.head()

# Shows the distribution of the amounts of fraudulent transactions
fig, ax = plt.subplots()
ghistogram = ax.hist(data_fraudulentas, bins=30)
ax.set_title('Distribution of fraudulent amounts')
ax.set_ylabel('Amount')
ax.set_xlabel('Count')
fig.show()

from sklearn.model_selection import train_test_split

y = data["Class"] # target variable
X = data.drop("Class", axis=1) # descriptive variables
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)
# we compare which are the final dimensions of the split
print('The dimensions of X_train are: ', X_train.shape)
print('The dimensions of y_train are: ', y_train.shape)
print('The dimensions of X_test are: ', X_test.shape)
print('The dimensions of y_test are: ', y_test.shape)

from sklearn.ensemble import RandomForestClassifier
randomforest = RandomForestClassifier(max_depth = 150, random_state = 42)
randomforest.fit(X_train, y_train)

predictions = randomforest.predict(X_test)

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
print(classification_report(y_test, predictions))

plt.figure(figsize=(6, 6))
sns.heatmap(confusion_matrix(y_test, predictions), annot=True, fmt="d", cmap="Blues", cbar=False, xticklabels=["No Fraud", "Fraud"], yticklabels=["No Fraud", "Fraud"])
# Labels and title
plt.xlabel("Prediction")
plt.ylabel("Reality")
plt.title("Confusion Matrix")
plt.show()

accuracy = accuracy_score(y_test, predictions)
print(f"{accuracy:.2f}")